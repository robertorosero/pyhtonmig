Securing Python
#####################################################################

Introduction
///////////////////////////////////////

As of Python 2.5, the Python does not support any form of security
model for
executing arbitrary Python code in some form of protected interpreter.
While one can use such things as ``exec`` and ``eval`` to garner a
very weak form of sandboxing, it does not provide any thorough
protections from malicious code.

This should be rectified.  This document attempts to lay out what
would be needed to secure Python in such a way as to allow arbitrary
Python code to execute in a sandboxed interpreter without worries of
that interpreter providing access to any resource of the operating
system without being given explicit authority to do so.

Throughout this document several terms are going to be used.  A
"sandboxed interpreter" is one where the built-in namespace is not the
same as that of an interpreter whose built-ins were unaltered, which
is called an "unprotected interpreter".

A "bare interpreter" is one where the built-in namespace has been
stripped down the bare minimum needed to run any form of basic Python
program.  This means that all atomic types (i.e., syntactically
supported types), ``object``, and the exceptions provided by the
``exceptions`` module are considered in the built-in namespace.  There
have also been no imports executed in the interpreter.


Rationale
///////////////////////////////////////

Python is used extensively as an embedded language within existing
programs.  These applications often times need to provide the
functionality of allowing users to run Python code written by someone
else where they can trust that no unintentional harm will come to
their system regardless of their trust of the code they are executing.

For instance, think of an application that supports a plug-in system
with Python as the language used for writing plug-ins.  You do not
want to have to examine every plug-in you download to make sure that
it does not alter your filesystem if you can help it.  With a proper
security model and implementation in place this hinderance of having
to examine all code you execute should be alleviated.


Approaches to Security
///////////////////////////////////////

There are essentially two types of security: who-I-am
(permissions-based) security and what-I-have (authority-based)
security.

Who-I-Am Security
========================

With who-I-am security (a.k.a., permissions-based security), the
ability to use a resource requires providing who you are, validating
you are allowed to access the resource you are requesting, and then
performing the requested action on the resource.

The ACL security system on most UNIX filesystems is who-I-am security.
When you want to open a file, say ``/etc/passwd``, you make the
function call to open the file.  Within that function, it fetchs
the ACL for the file, finds out who the caller is, checks to see if
the caller is on the ACL for opening the file, and then proceeds to
either deny access or return an open file object.


What-I-Have Security
========================

A contrast to who-I-am security, what-I-have security never requires
knowing who is requesting a resource.  By never providing a function
to access a resource or by creating a proxy that wraps the function to
access a resource with argument checking, you can skip the need to
know who is making a call.

Using our file example, the program trying to open a file is given a
proxy that checks whether paths passed into the function match allowed
based at the creation time of the proxy before using the full-featured
open function to open the file.

This illustrates a subtle, but key difference between who-I-am and
what-I-have security.  For who-I-am, you must know who the caller is
and check that the arguments are valid for the person calling.  For
what-I-have security, you only have to validate the arguments.


Object-Capabilities
///////////////////////////////////////

What-I-have security is more often called the object-capabilities
security model.  The belief here is in POLA (Principle Of Least
Authority): you give a program exactly what it needs, and no more.  By
providing a function that can open any file that relies on identity to
decide if to open something, you are still providing a fully capable
function that just requires faking one's identity to circumvent
security.  It also means that if you accidentally run code that
performs actions that you did not expect (e.g., deleting all your
files), there is no way to stop it since it operates with *your*
permissions.

Using POLA and object-capabilities, you only give access to resources
to the extent that someone needs.  This means if a program only needs
access to a single file, you only give them a function that can open
that single file.  If you accidentally run code that tries to delete
all of your files, it can only delete the one file you authorized the
program to open.

Object-capabilities use the reference graph of objects to provide the
security of accessing resources.  If you do not have a reference to a
resource (or a reference to an object that can references a resource),
you cannot access it, period.  You can provide conditional access by
using a proxy between code and a resource, but that still requires a
reference to the resource by the proxy.

This leads to a much cleaner implementation of security.  By not
having to change internal code in the interpreter to perform identity
checks, you can instead shift the burden of security to proxies
which are much more flexible and have less of an adverse affect on the
interpreter directly (assuming you have the basic requirements for
object-capabilities met).


Difficulties in Python for Object-Capabilities
//////////////////////////////////////////////

In order to provide the proper protection of references that
object-capabilities require, you must set up a secure perimeter
defense around your security domain.  The domain can be anthing:
objects, interpreters, processes, etc.  The point is that the domain
is where you draw the line for allowing arbitrary access to resources.
This means that with the interpreter is the security domain, then
anything within an interpreter can be expected to be freely shared,
but beyond that, reference access is strictly controlled.

Three key requirements for providing a proper perimeter defence is
private namespaces, immutable shared state across domains, and
unforgeable references.  Unfortunately Python only has one of the
three requirements by default (you cannot forge a reference in Python
code).


Problem of No Private Namespace
===============================

Typically, in languages that are statically typed (like C++), you have
public and private attributes on objects.  Those private attributes
provide a private namespace for the class and instances that are not
accessible by other objects.

The Python language has no such thing as a private namespace.  The
language has the philosophy that if exposing something to the
programmer could provide some use, then it is exposed.  This has led
to Python having a wonderful amount of introspection abilities.
Unfortunately this makes the possibility of a private namespace
non-existent.  This poses an issue for providing proxies for resources
since there is no way in Python code to hide the reference to a
resource.

Luckily, the Python virtual machine *does* provide a private namespace,
albeit not for pure Python source code.  If you use the Python/C
language barrier in extension modules, you can provide a private
namespace by using the struct allocated for each instance of an
object.  This provides a way to create proxies, written in C, that can
protect resources properly.  Throughout this document, when mentioning
proxies, it is assumed they have been implemented in C.


Problem of Mutable Shared State
===============================

Another problem that Python's introspection abilties cause is that of
mutable shared state.  At the interpreter level, there has never been
a concerted effort to isolate state shared between all interpreters
running in the same Python process.  Sometimes this is for performance
reasons, sometimes because it is just easier to implement this way.
Regardless, sharing of state that can be influenced by another
interpreter is not safe for object-capabilities.

To rectify the situation, some changes will be needed to some built-in
objects in Python.  It should mostly consist of abstracting or
refactoring certain abilities out to an extension module so that
access can be protected using import guards.


Threat Model
///////////////////////////////////////

The threat that this security model is attempting to handle is the
execution of arbitrary Python code in a sandboxed interpreter such
that the code in that interpreter is not able to harm anything outside
of itself.  This means that:

* An interpreter cannot influence another interpreter directly at the
  Python level without explicitly allowing it.
    + This includes preventing communicating with another interpreter.
    + Mutable objects cannot be shared between interpreters without
      explicit allowance for it.
    + "Explicit allowance" includes the importation of C extension
      modules because a technical detail requires that these modules
      not be re-initialized per interpreter, meaning that all
      interpreters in a single Python process share the same C
      extension modules.
* An interpreter cannot use operating system resources without being
  explicitly given those resources.
    + This includes importing modules since that requires the ability
      to use the resource of the filesystem.

In order to accomplish these goals, certain things must be made true.

* The Python process is the "powerbox".
    + It controls the initial granting of abilties to interpreters.
* A bare Python interpreter is always trusted.
    + Python source code that can be created in a bare interpreter is
      always trusted.
    + Python source code created within a bare interpreter cannot
      crash the interpreter.
* Python bytecode is always distrusted.
    + Malicious bytecode can bring down an interpreter.
* Pure Python source code is always safe on its own.
    + Malicious abilities are derived from C extension modules,
      built-in modules, and unsafe types implemented in C, not from
      pure Python source.
* A sub-interpreter started by another interpreter does not inherit
  any state.
    + The sub-interpreter starts out with a fresh global namespace and
      whatever built-ins it was initially given.


Implementation
///////////////////////////////////////

Guiding Principles
========================

To begin, the Python process garners all power as the powerbox.  It is
up to the process to initially hand out access to resources and
abilities to interpreters.  This might take the form of an interpreter
with all abilities granted (i.e., a standard interpreter as launched
when you execute Python), which then creates sub-interpreters with
sandboxed abilities.  Another alternative is only creating
interpreters with sandboxed abilities (i.e., Python being embedded in
an application that only uses sandboxed interpreters).

All security measures should never have to ask who an interpreter is.
This means that what abilities an interpreter has should not be stored
at the interpreter level when the security can use a proxy to protect
a resource.  This means that while supporting a memory cap can
have a per-interpreter setting that is checked (because access to the
operating system's memory allocator is not supported at the program
level), protecting files and imports should not such a per-interpreter
protection at such a low level (because those can have extension
module proxies to provide the security).

For common case security measures, the Python standard library
(stdlib) should provide a simple way to provide those measures.  Most
commonly this will take the form of providing factory functions that
create instances of proxies for providing protection of key resources.

Backwards-compatibility will not be a hindrance upon the design or
implementation of the security model.  Because the security model will
inherently remove resources and abilities that existing code expects,
it is not reasonable to expect existing code to work in a sandboxed
interpreter.

Keeping Python "pythonic" is required for all design decisions.  If
removing an ability leads to something being unpythonic, it will not
be done.  This does not mean existing pythonic code must continue to
work, but the spirit of being pythonic will not be compromised in the
name of the security model.  While this might lead to a weaker
security model, this is a price that must be paid in order for Python
to continue to be the language that it is.

Restricting what is in the built-in namespace and the safe-guarding
the interpreter (which includes safe-guarding the built-in types) is
where security will come from.  Imports and the ``file`` type are
both part of the standard namespace and must be restricted in order
for any security implementation to be effective.
The built-in types which are needed for basic Python usage (e.g.,
``object`` code objects, etc.) must be made safe to use in a sandboxed
interpreter since they are easily accessbile and yet required for
Python to function.


Abilities of a Standard Sandboxed Interpreter
=============================================

In the end, a standard sandboxed interpreter should (not)
allow certain things to be doable by code running within itself.
Below is a list of abilities that will (not) be allowed in the default
instance of a sandboxed interpreter comparative to an unprotected
interpreter that has not imported any modules.  These protections can
be tweaked by using proxies to allow for certain extended abilities to
be accessible.

* You cannot open any files directly.
* Importation
    + You can import any pure Python module.
    + You cannot import any Python bytecode module.
    + You cannot import any C extension module.
    + You cannot import any built-in module.
* You cannot find out any information about the operating system you
  are running on.
* Only safe built-ins are provided.


Implementation Details
========================

An important point to keep in mind when reading about the
implementation details for the security model is that these are
general changes and are not special to any type of interpreter,
sandboxed or otherwise.  That means if a change to a built-in type is
suggested and it does not involve a proxy, that change is meant
Python-wide for *all* interpreters.


Imports
-------

A proxy for protecting imports will be provided.  This is done by
setting the ``__import__()`` function in the built-in namespace of the
sandboxed interpreter to a proxied version of the function.

The planned proxy will take in a passed-in function to use for the
import and a whitelist of C extension modules and built-in modules to
allow importation of.  If an import would lead to loading an extension
or built-in module, it is checked against the whitelist and allowed
to be imported based on that list.  All .pyc and .pyo file will not
be imported.  All .py files will be imported.

XXX perhaps augment 'sys' so that you list the extension of files that
can be used for importing?  Thought this was controlled somewhere
already but can't find it.

It must be warned that importing any C extension module is dangerous.
Not only are they able to circumvent security measures by executing C
code, but they share state across interpreters.  Because an extension
module's init function is only called once for the Python *process*,
its initial state is set only once.  This means that if some mutable
object is exposed at the module level, a sandboxed interpreter could
mutate that object, return, and then if the creating interpreter
accesses that mutated object it is essentially communicating and/or
acting on behalf of the sandboxed interpreter.  This violates the
perimeter defence.  No one should import extension modules blindly.


Sanitizing Built-In Types
-------------------------

Python contains a wealth of bulit-in types.  These are used at a basic
level so that they are easily accessible to any Python code.  They are
also shared amongst all interpreters in a Python process.  This means
all built-in types need to be made safe (e.g., immutable shared
state) so that they can be used by any and all interpreters in a
single Python process.  Several aspects of built-in types need to be
examined.


Constructors
++++++++++++

Almost all of Python's built-in types
contain a constructor that allows code to create a new instance of a
type as long as you have the type itself.  Unfortunately this does not
work in an object-capabilities system without either providing a proxy
to the constructor or just turning it off.

The plan is to turn off the constructors that are currently supplied
directly by the types that are dangerous.  Their constructors will
then either be shifted over to factory functions that will be stored
in a C extension module or to built-ins  that will be
provided to use to create instances.  The former approach will allow
for protections to be enforced by import proxy; just don't allow the
extension module to be imported.  The latter approach would allow
either a unique constructor per type, or more generic built-in(s) for
construction (e.g., introducing a ``construct()`` function that takes
in a type and any arguments desired to be passed in for constructing
an instance of the type) and allowing using proxies to provide
security.

Some might consider this unpythonic.  Python very rarely separates the
constructor of an object from the class/type and require that you go
through a function.  But there is some precedent for not using a
type's constructor to get an instance of a type.  The ``file`` type,
for instance, typically has its instances created through the
``open()`` function.  This slight shift for certain types to have their
(dangerous) constructor not on the type but in a function is
considered an acceptable compromise.

Types whose constructors are considered dangerous are:

* ``file``
    + Will definitely use the ``open()`` built-in.
* code objects
* XXX sockets?
* XXX type?
* XXX


Filesystem Information
++++++++++++++++++++++

When running code in a sandboxed interpreter, POLA suggests that you
do not want to expose information about your environment on top of
protecting its use.  This means that filesystem paths typically should
not be exposed.  Unfortunately, Python exposes file paths all over the
place:

* Modules
    + ``__file__`` attribute
* Code objects
    + ``co_filename`` attribute
* Packages
    + ``__path__`` attribute
* XXX

XXX how to expose safely?


Mutable Shared State
++++++++++++++++++++

Because built-in types are shared between interpreters, they cannot
expose any mutable shared state.  Unfortunately, as it stands, some
do.  Below is a list of types that share some form of dangerous state,
how they share it, and how to fix the problem:

* ``object``
    + ``__subclasses__()`` function
        - Remove the function; never seen used in real-world code.
* XXX


Perimeter Defences Between a Created Interpreter and Its Creator
----------------------------------------------------------------

The plan is to allow interpreters to instantiate sandboxed
interpreters safely.  By using the creating interpreter's abilities to
provide abilities to the created interpreter, you make sure there is
no escalation in abilities.

But by creating a sandboxed interpreter and passing in any code into
it, you open up the chance of possible ways of getting back to the
creating interpreter or escalating privileges.  Those ways are:

* ``__del__`` created in sandboxed interpreter but object is cleaned
  up in unprotected interpreter.
* Using frames to walk the frame stack back to another interpreter.
* XXX


Making the ``sys`` Module Safe
------------------------------

XXX


Safe Networking
---------------

XXX
